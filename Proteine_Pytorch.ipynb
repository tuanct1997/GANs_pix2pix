{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(\".//Data//protein-secondary-structure.train\", \"r\")\n",
    "test_data = open(\".//Data//protein-secondary-structure.test\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the windows size and (training, validation) spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_slide = 5\n",
    "train_size = 80\n",
    "validation_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = train_data.readline()\n",
    "line = 1\n",
    "x_train = []\n",
    "y_train = []\n",
    "nb_proteine = 0\n",
    "while d_train:\n",
    "    if line > 8:\n",
    "        if len(d_train) == 1:\n",
    "            pass\n",
    "        elif d_train == '<>\\n':\n",
    "            if len(x_train) !=0 and x_train[len(x_train) -1] != '%':\n",
    "                x_train.append('%')\n",
    "            nb_proteine += 1\n",
    "            x_train.append('%')\n",
    "        elif d_train == 'end\\n':\n",
    "            x_train.append('%')\n",
    "        elif d_train == '<end>\\n':\n",
    "            x_train.append('%')\n",
    "        else:\n",
    "            x_train.append(d_train[0])\n",
    "            y_train.append(d_train[2])\n",
    "            \n",
    "        \n",
    "    d_train = train_data.readline()\n",
    "    line += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "line = 1\n",
    "x_test = []\n",
    "y_test = []\n",
    "for k in range(int(window_slide/2) - 1):\n",
    "    x_test.append('%')\n",
    "    \n",
    "d_test = test_data.readline()\n",
    "while d_test:\n",
    "    if line > 8:\n",
    "        if len(d_test) == 1:\n",
    "            pass\n",
    "        elif d_test == '<>\\n':\n",
    "            if len(x_test)!=0 and x_test[len(x_test) -1] != '%':\n",
    "                x_test.append('%')\n",
    "            x_test.append('%')\n",
    "        elif d_test == '<end>\\n':\n",
    "            x_test.append('%')\n",
    "            for k in range(int(window_slide/2) - 1):\n",
    "                x_test.append('%')\n",
    "        else:\n",
    "            x_test.append(d_test[0])\n",
    "            y_test.append(d_test[2])\n",
    "        \n",
    "    d_test = test_data.readline()\n",
    "    line += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data into Training, Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = int(nb_proteine * train_size)\n",
    "nb_valid = nb_proteine - nb_train\n",
    "x_train_split = {'x_train_':[],'x_valid_':[]}\n",
    "y_train_split = {'y_train_':[],'y_valid_':[]}\n",
    "length_train_ = 0\n",
    "length_valid_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "r = 0\n",
    "for k in range(int(window_slide/2) - 1):\n",
    "                x_train_split['x_train_'].append('%')\n",
    "for k in range(int(window_slide/2) - 1):\n",
    "                x_train_split['x_valid_'].append('%')\n",
    "        \n",
    "for k in range(len(x_train)):\n",
    "    if x_train[k] == '%' and (k + 1)!= len(x_train) and x_train[k + 1] != '%':\n",
    "        r = random.choice([0,1])\n",
    "        if r ==0 and len(y_train_split['y_train_']) == nb_train:\n",
    "            r = 1\n",
    "        if r ==1 and len(y_train_split['y_valid_']) == nb_valid:\n",
    "            r = 0\n",
    "        if r == 0:\n",
    "            length_train_ += 1\n",
    "        else:\n",
    "            length_valid_ += 1\n",
    "            \n",
    "    if r == 0:\n",
    "        x_train_split['x_train_'].append(x_train[k])\n",
    "        if x_train[k] != '%':\n",
    "            y_train_split['y_train_'].append(y_train[l])\n",
    "            l += 1\n",
    "    else:\n",
    "        x_train_split['x_valid_'].append(x_train[k])\n",
    "        if x_train[k] != '%':\n",
    "            y_train_split['y_valid_'].append(y_train[l])\n",
    "            l += 1\n",
    "            \n",
    "for k in range(int(window_slide/2) - 1):\n",
    "                x_train_split['x_train_'].append('%')\n",
    "for k in range(int(window_slide/2) - 1):\n",
    "                x_train_split['x_valid_'].append('%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(y_train_split['y_valid_']) + len(y_train_split['y_train_']))\n",
    "#print(len(y_train))\n",
    "#print(length_train_+length_valid_)\n",
    "#print(x_train_split['x_train_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[int(window_slide/2):21 + int(window_slide/2)])\n",
    "#print(y_train[:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_test[int(window_slide/2):21 + int(window_slide/2)])\n",
    "#print(y_test[:21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coversion tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convesion_input_data = {'%':0,'A':1,'C':2, 'D':3,'E':4,'F':5,'G':6, 'H':7, 'I':8, 'K':9, 'L':10, 'M':11, 'N':12, 'P':13,\n",
    "                    'Q':14, 'R':15, 'S':16, 'T':17, 'V':18, 'W':19, 'Y':20}\n",
    "convesion_output_data = {'_':0, 'e':1, 'h':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_converted = []\n",
    "y_train_converted = []\n",
    "x_valid_converted = []\n",
    "y_valid_converted = []\n",
    "x_test_converted = []\n",
    "y_test_converted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(x_train_split['x_train_'])):\n",
    "    x_train_converted.append(convesion_input_data[x_train_split['x_train_'][k]])\n",
    "    \n",
    "for k in range(len(x_train_split['x_valid_'])):\n",
    "    x_valid_converted.append(convesion_input_data[x_train_split['x_valid_'][k]])\n",
    "    \n",
    "for k in range(len(x_test)):\n",
    "    x_test_converted.append(convesion_input_data[x_test[k]])\n",
    "    \n",
    "for k in range(len(y_train_split['y_train_'])):\n",
    "    y_train_converted.append(convesion_output_data[y_train_split['y_train_'][k]])\n",
    "    \n",
    "for k in range(len(y_train_split['y_valid_'])):\n",
    "    y_valid_converted.append(convesion_output_data[y_train_split['y_valid_'][k]])\n",
    "    \n",
    "for k in range(len(y_test)):\n",
    "    y_test_converted.append(convesion_output_data[y_test[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_one_hot = np.array(F.one_hot(torch.tensor(x_train_converted), num_classes=21))\n",
    "x_valid_one_hot = np.array(F.one_hot(torch.tensor(x_valid_converted),  num_classes=21))\n",
    "x_test_one_hot = np.array(F.one_hot(torch.tensor(x_test_converted),  num_classes=21))\n",
    "\n",
    "y_train_one_hot = np.array(F.one_hot(torch.tensor(y_train_converted),  num_classes=3))\n",
    "y_valid_one_hot = np.array(F.one_hot(torch.tensor(y_valid_converted), num_classes=3))\n",
    "y_test_one_hot = np.array(F.one_hot(torch.tensor(y_test_converted), num_classes=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_test_converted[:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_test_one_hot[:21][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = []\n",
    "x_valid_final = []\n",
    "x_test_final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(x_train_converted)):\n",
    "    if x_train_converted[k] != 0:\n",
    "        data = []\n",
    "        val = int(window_slide/2)\n",
    "        for l in range(window_slide):\n",
    "            data.extend(x_train_one_hot[l + k - val].copy())\n",
    "        x_train_final.append(data.copy())\n",
    "        \n",
    "for k in range(len(x_valid_converted)):\n",
    "    if x_valid_converted[k] != 0:\n",
    "        data = []\n",
    "        val = int(window_slide/2)\n",
    "        for l in range(window_slide):\n",
    "            data.extend(x_valid_one_hot[l + k - val].copy())\n",
    "        x_valid_final.append(data.copy())\n",
    "        \n",
    "for k in range(len(x_test_converted)):\n",
    "    if x_test_converted[k] != 0:\n",
    "        data = []\n",
    "        val = int(window_slide/2)\n",
    "        for l in range(window_slide):\n",
    "            data.extend(x_test_one_hot[l + k - val].copy())\n",
    "        x_test_final.append(data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = np.array(x_train_final,dtype=int)\n",
    "x_valid_final = np.array(x_valid_final,dtype=int)\n",
    "x_test_final = np.array(x_test_final,dtype=int)\n",
    "#print(x_train_final[0])\n",
    "#print(y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(MLP, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 3)\n",
    "            self.softmax = torch.nn.Softmax(dim=1)\n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            relu = self.relu(hidden)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.softmax(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(105, 100)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.6475067734718323\n",
      "Epoch 1: train loss: 0.6471641659736633\n",
      "Epoch 2: train loss: 0.6468229293823242\n",
      "Epoch 3: train loss: 0.6464830636978149\n",
      "Epoch 4: train loss: 0.6461443305015564\n",
      "Epoch 5: train loss: 0.6458069682121277\n",
      "Epoch 6: train loss: 0.6454707980155945\n",
      "Epoch 7: train loss: 0.6451359391212463\n",
      "Epoch 8: train loss: 0.6448025107383728\n",
      "Epoch 9: train loss: 0.64447021484375\n",
      "Epoch 10: train loss: 0.6441392302513123\n",
      "Epoch 11: train loss: 0.6438096165657043\n",
      "Epoch 12: train loss: 0.6434812545776367\n",
      "Epoch 13: train loss: 0.6431540846824646\n",
      "Epoch 14: train loss: 0.6428281664848328\n",
      "Epoch 15: train loss: 0.6425036191940308\n",
      "Epoch 16: train loss: 0.642180323600769\n",
      "Epoch 17: train loss: 0.6418582797050476\n",
      "Epoch 18: train loss: 0.6415374875068665\n",
      "Epoch 19: train loss: 0.6412180066108704\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch = 20\n",
    "x_train_final = torch.tensor(x_train_final,  dtype=torch.float)\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train_final)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred, torch.tensor(y_train_one_hot,  dtype=torch.float))\n",
    "   \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.6414985656738281\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(torch.tensor(x_test_final,  dtype=torch.float))\n",
    "loss = criterion(y_pred, torch.tensor(y_test_one_hot,  dtype=torch.float))\n",
    "print('Test loss' , loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
